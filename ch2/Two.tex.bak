\chapter{Background}
The ambitious scope of this project requires a thorough grounding in the literature from a range of disciplines.  The risk in such an inclusive undertaking is that there are many opportunities for going astray.  The reward, a piece of empirical work that exemplifies the possibility of using computers to do theoretically significant research, seems to justify the risk, but only if the final product is well placed in the context of existing work in the area.  The following chapter will delineate the territory that this thesis seeks to explore, by way of a survey of the considerable canon of theoretical work relating to the problems of minds, concepts, and language as well as the increasingly substantial body of practical work on computational linguistics and its application to the modelling of creative language generation.

\section{Computers, Creativity, and Making Meaning}
At its heart, this is a project about how meaning comes about in a reality which, as scientists, we accept as being fundamentally materialist.  The question of the place of the mind -- the instrument of meaning making -- in relation to the realm of matter has been arguably the unifying theme of modern Western Philosophy, dating back to the \emph{cogito} of \cite{Descartes} and serving as the broad target of subsequent forays into empiricism \citep{Locke,Hume}, conceptual innatism \citep{Kant}, idealism \citep{Hegel}, intentionality \cite{Bretano}, phenomenology \citep{Husserl,Heidegger}, and the verity of metaphysics itself \citep{Wittgenstein}.  In the case of the last philosopher in particular, the project described here is concerned with what Wittgenstein has described as ``the act of meaning'', that process by which being in the world as a communicative agent somehow results in the emergence of intention from the particulate morass, an evident \emph{creatio ex nihilo}.

The recent trend in philosophy, not to mention in empirically fastidious fields such as cognitive science and psychology, has been towards a resolute materialist reductionism, to such an extent that \cite{Rowlands} reports that in the current cognitive scientific milieu, ``even the word `Cartesian' is often used as a term of abuse,'' (p. 12).  Those thinkers who do indulge in dualist theories of mind -- and here \cite{Chalmers1996} and \cite{Fodor2008} are two of the most notable examples -- do so by means of subtle argumentation and elaborate analogy.\footnote{Chalmers's version of the ``philosophical zombies'' argument has been particularly persistent here, though parallels between this and the earlier ``swampman'' scenario from \cite{Davidson} and the self-manifesting lion of \cite{Millikan} have been arguably underexplored in the literature.  The fact that thought experiments have proved so prodigious a source of ideas about the mind is in itself noteworthy, and is addressed in a certain respect in \citepos{Dennett} case against ``intuition pumps''.}  By and large, though, there is a broad acceptance that the mind must somehow supervene upon physical reality, ranging from the strictly eliminativist neurophilosophy of \cite{Churchland} to the emergentist enactivism of \cite{Thompson} and \cite{Hutto}.  As \cite{Deacon} has put it in his biologically grounded account of the emergence of goal-directed behaviour, ``Such concepts as information, function, purpose, meaning, intention, significance, consciousness, and value are intrinsically defined by their fundamental incompleteness,'' (p. 23)

%The debate that has emerged amongst those researchers interested in the nature of the mind in the place of the old question of mental substance is focused on the extent to which the mind can be considered as a kind of computer versus the degree to which the mind can only be understood as an emergent property of an agent deeply entangled with a dynamic and unpredictable environment.  On the one hand, \cite{Fodor} has argued for a combinatorial computer-like model of cognition characterised by a \emph{mentalese} through which atomic concepts can be composed into a presumably infinite and infinitely efficacious 

%On the other hand, \cite{Searle} has argued forcefully from an \emph{intentional stance} by which a mind is what it is because mental states are about things in the world, an intentionality which is necessarily intractable to a preprogrammed symbol manipulating system

%while \cite{Penrose} has elegantly imported the logical certitude of \citepos{Goedel} Uncertainty Principle to demonstrate the inconceivability of purely formal model of mind.

%has resulted in a productive if also occasionally acrimonious discourse \citep[see][for a particularly colourful 

So the theoretical question which underlies the empirical research presented in this thesis regards the way in which meaning emerges in a universe of particles and signals.  This question is related to \citepos{Floridi} pursuit of a \emph{theory of strongly semantic information}---doubly so, in that, like Floridi, we will seek a quantitative approach to modelling the relationship between semantics and data, in the information theoretical tradition of \cite{Shannon}.  An early attempt to import technical insight from signal processing into the study of meaning can be found in \citepos{BarHillel}, who use Shannon-type metrics as the basis for quantifying the inferential properties associated with the semantic content of sentences, followed by \cite{Dretske}, who described the formation of meaningful concepts in terms of the development of internal semantic structures that evolve to indicatively correspond with quantifiable informational situations in an environment.  Subsequent forays in a \emph{situation logic} designed to model semantic information content in a way which is simultaneously measurable and context specific \citep{BarwiseEA} have led to a 

Returning to the question of the \emph{epistemic gap} between mind and matter \citep{Levine,Pattee}, \cite{Tonnoni} has proposed an information-theoretic metric for assessing the degree of consciousness exhibited by a system, an idea which \cite{Koch} has pursued to the extent of proposing a panpsychicism by which any system in the universe has a quantifiable degree of consciousness.

In the spirit of these quantitative approaches to meaning, the work presented in this thesis seeks a data processing approach to modelling semantics---an approach which is computationally tractable but at the same time avoids committing to the case that the mind is in a computer in anything other than the most metaphoric of senses.  Furthermore,  when it comes to the emergence of meaning, creativity is a kind of watchword to keep us faithful to the question of how meaning 

\cite{Koestler1964} has argued that creativity is about generating new connections 

With regard to this question concerning the emergence of meaning, creativity serves as a kind of watchword, a beacon to keep us faithful to the issue of how artefacts can be about ideas in the 

we are concerned, fundamentally, with the aboutness of mental states, and likewise conscious of the pitfalls of trying to cash these states out as computations.

The study of computational creativity in particular neatly aligns the 

with the philosophical dilemma of the relationship between minds and computation as a broad

Searle

At stake here is, in at least small part, a definition of \emph{creativity} itself, and \cite{Colton} has pointed out that this term must be considered ``essentially contested,''

Nonetheless, the approach towards creativity 

and if we can discover a reasonably convincing computational approach to modelling creativity, then we will likewise have discovered the ways in which 

\section{Concepts}

that concerns itself with the emergence of meaning in the universe needs to likewise be grounded in a concrete sense of what constitutes a concept, as concepts are

\cite{Fodor}, who holds that concepts are fundamentally composable and, at least in some instances, atomic mental entities

what is a concept?  \cite{Fodor} has endorsed a kind of \emph{atomism} in 

\citep[cf][for a case against conceptual schema in general]{Davidson}

The work presented in this thesis embraces the insights of Relevance Theory, which broadly postulates that 

\cite{Carston} has described this 

- Lakoff
- Davidson
- Turner, Turner & Fauconnier
- Sowa
- Haspelmath
- Structure Mapping Engine
- Relevance Theory
- Hannu on conceptual blending

Remarkably -- or, perhaps, predictably -- \cite{Kant} remains imminently relevant here.  His notion of an innate faculty of \emph{intuition} grounded in the fundamentally geometric nature of the mental experience of reality prefigures the ongoing debate between those who hold that 

One might even suggest that Kant offers a way out 

\section{Words}
Language is the point at which the abstractions surveyed in the last section make contact with palpable data: a mainstay of the so-called Cognitive Revolution, kicked off by \citepos{Chomsky1959} pointed denouncement of \citepos{Skinner1957} attempt to apply overt psychological behaviouralism to the study of language, has been the idea that language, more than simple signalling, can only be understood in terms of reflecting mental content.  Indeed, there are some thinkers who would go so far as to argue, as \cite{Dennett1996} seems to, that having language is a necessary condition for having what is thought of as a mind---\citepos{Fodor1975} notion of a language of thought, as described above, could likewise be construed as tantamount to such a stance.  The notion of language as either an impediment or an incipient to pure thought was essential to \cite{Russell1905,Russell1931}, and was also a primary theme for \citepos{Wittgenstein1922} earlier work.  Certainly, the idea that having a human-like mind is the necessary condition for having language, if not the other way around, has been the abiding theme in development of \citepos{Chomsky} nativist programme of research as well as the psychological projects of some of his acolytes \citep{Pinker1994}.

transformational grammar
Intensional semantics

Meanwhile, \cite{Peirce1931} advocated the idea that the signs constituting a language are involved in a physically grounded process that is perpetually unfolding in tight entanglement with the world.  While Peirce's work was fated to academic obscurity until the later 20th Century, the theme of the environmentally situated character of language would return to prominence with the later pragmatics of \cite{Grice1975},\footnote{The application of the label \emph{pragmatics} to describe the work of Peirce and some of his contemporaries as compared to the latter day efforts of Grice and his cohorts probably indicates a coincidence of intent rather than a scholastic continuum, but there is nonetheless an incidental correspondence to be analysed---see \cite{Pietarinen2004} for a treatment.} whose formulation of implicature encapsulated the idea that linguistic meaning is resolved contextually.  The passage of language from the mind into the environment precipitates what \cite{Eco1976} characterises in his analysis of Peirce as an \emph{infinite semiosis} by which the world of things is constantly flowing into the world of representations.  \citepos{Fillmore1976} subsequently contributed his notion of \emph{frame semantics} as a model for the resolution of word meaning in terms of a broader \emph{encyclopedic} understanding of the conceptual situation of semantics.

The work of Grice and Fillmore presaged a cognitive turn in linguistics, characterised by \citepos{Langacker1987} description of natural language as ``dependent on experiential factors and inextricably bound up with psychological phenomena that are not explicitly linguistic in nature,'' (p. 13).  Where the tradition of formal semantics, as typified by the compositionality of Montague grammar \citep{Cooper} and the inferential capacity of intensional semantics \citep{FoxEA2005}, has focused on questions of quantification and logic, cognitive linguistics has been more concerned with relating linguistic phenomena to other cognitively pertinent domains, such as culture \citep{Lakoff1987} and neuroscience \cite{Feldman2006}.  \cite{Sweetser1990} focuses on the inescapable ambiguity of lexical semantics arising from the way that the meaning of words is selected based on a cognitive situation.  And \cite{Evans2009} goes so far as to suggest that meaning should only be applied at the level of utterances made in context, thereby abandoning the Fregean aspect of Montegovian semantics \citep{Dummett1981} altogether.

Given this ambivalence towards lexical stability, it is hardly surprising that phenomena of non-literal language use such as metaphor have been of particular interest to cognitive linguists.  A flurry of theoretical activity in the late 1970s and early 1980s saw the emergence of \citepos{Ortony1975} reconstructivist account of metaphor, the resurgence of \citepos{Black1955,Black1977} \emph{interaction view},  and, most notably, the introduction of \citepos{LakoffEA1980} \emph{conceptual} model of metaphor \citep[see][for a valuable compendium]{Ortony1993}.  The gist of all these accounts was that metaphor, rather than being an anomalous violation of rigid semantic protocol, is in fact a central component of the way that language is used to structure and communicate about conceptual schemes, with \cite{Gibbs1994} calling upon scholars to ``recognize metaphor as a primary mode of thought,'' (p. 122).

A related linguistic phenomenon, likewise with its roots in the cognitive linguistic paradigm, is semantic type coercion.

While it has been theoretically productive, this aspect of linguistics has received considerably less attention from computer scientists, with one of the standout contributions being the task described by \cite{PustejovskyEA2010}, the data for which will provide the foundation for some of the empirical work described in Chapter~\ref{chap:figurative}.

Some early computational approaches to metaphor maintained an essentially formal character: \cite{vanGenabith2001} proposed a type theoretical model for describing metaphor.  Information processing approaches have, though, been by and large data-driven, understandably utilising the processing power of symbol manipulating machines---and these data-driven approaches have generally had some sort of connection with the cognitive linguistic stances on metaphor.  So, for instance, \cite{ThomasEA1999} describe an information processing network which selectively projects features, inspired by the previously mentioned interactive view of metaphor developed by \cite{Black1977}.  In terms of theoretical grounding, \cite{Shutova2010} identifies the \emph{selectional preference violation} approach of \cite{Wilks1978} as especially influential, perhaps because it was formulated specifically as an information processing mechanism.\footnote{Though it is not explicitly mentioned, there seems to be a clear correspondence between Wilks's approach and the idea of \cite{Grice} and subsequently \cite{Searle1979} that metaphor constitutes language use ``that departs from from what the word, expression, or sentence actually means,'' \citep[][p. 84]{Searle1979}.}  A notable early effort from \cite{Fass1991} is derived from this theoretical background, with correspondences in the selectional preference of the arguments of verbs used to detect metonymic versus metaphoric uses of language (and there is a connection to be drawn here with the ideas about type coercion discussed above, as well). In a subsequent comprehensive review of computational metaphor, \cite{Shutova2015} acknowledges that ``it is the principles of CMT [the conceptual metaphor theory of \cite{LakoffEA1980}] that inspired and influenced much of the computational work on metaphor,'' (p. 580), and most of the technical approaches that will now be surveyed are to some extent rooted in this theoretic paradigm.

One trend in the computational modelling of metaphor has focused on symbolic constructs, and in this regard has found a correspondence with some of the concept modelling techniques described in the previous section.  This has generally involved mapping between conceptual schemes \citep{Indurkhya1997}, often domain specific, with the underlying assumption that mappings between domains correlates with the conceptual metaphor model \citep{Narayanan1999}.  Typical symbolic approaches to metaphor modelling involve the construction of an ontology defined by features which can be mapped between elements.  The ATT-Meta system \citep{LeeEA2001}, with its faculty for backchaining inferences across conceptual domains, is exemplary, and has furthermore been expanded into a metaphor generating system employing a combination of distributional semantic and incremental grammar techniques \citep{GargettEA2013}.  Other symbolic approaches are notable for their recourse to preformulated knowledge bases such as WordNet

Twitter \citep{VealeEA2015}, or the web at large in conjunction with other resources \citep{VealeEA2007}.

Symbolic approaches have tended to focus on the interpretation of metaphor by way of models of trans-conceptual mappings, but in another aspect of computational work, that of metaphor identification, statistical approaches have proved particularly effective.\footnote{\cite{Shutova2013} suggests that computational identification and interpretation of metaphor, in line with psychological analysis, should be considered a joint task.}  An early example is the TroFi model of \cite{BirkeEA2006}, which uses a clustering algorithm trained on a set of tagged sample sentences to disambiguate between literal and non-literal verb use, followed by \cite{Utsumi2011}, who explores clustering in the context of distributional semantics.  Indeed, many of these statistical approaches (see \citealt{TurneyEA2011}, \citealt{Dunn2013} for a comparison of distributional semantic and symbolic models, \citealt{ShutovaEA2013} for an overview of statistical models in particular) have employed the techniques of distributional semantics, which will be discussed in the next section: here \citepos{Kintsch2000} model of metaphoric interpretation as a contextually selective traversal of the space between word-vectors is seminal.  A notable recent instance of a statistical model for metaphor identification involving an application of compositional distributional semantics is described by \cite{GutierrezEA2016}, of particular note here as the dataset presented by those authors will be used to evaluate the model at the heart of this thesis (see Chapter~\ref{chap:figurative} for a more detailed description).

Returning to the cognitive linguistic foundations of computational approaches to metaphor, \cite{TsvetkovEA2014} propose that their results ``support the hypothesis that metaphors are conceptual, rather than lexical, in nature,'' (p. 248).  A further theoretical twist, however, has motivated the empirical work presented in this thesis.  In his controversial work roughly contemporary to the emergence of cognitive approaches to metaphor, \cite{Davidson1974}

\footnote{While Davidson's approach to metaphor has arguably been conspicuous in its absence from the computational literature, it has recently been addressed by \cite{Veale2016}.}

Again following \cite{Davidson}, ``there are no unsuccessful metaphors''--any combination of 

\section{Word Counting}
Finally, the technical methodology of this project is grounded in recent and ongoing success in statistical approaches to language modelling.  The tradition of word-counting in order to predict sequences in language traces its roots back to the fastidious work of \cite{Markov}, who tabulated co-occurrences of characters in Pushkin's \emph{Eugene Onegin} by hand.  The research described in this thesis is situated within the paradigm of \emph{distributional semantics} which has its roots in \citepos{Harris1954} work examining ``meaning as a function of distribution,'' (p. 155).  The guiding principle of this area of research is the idea that ``words that occur in the same contexts tend to have similar meaning,'' \citep[][p. 126]{Pantel2005}.  Other early work in the field included 

who were generally confined to theoretical output due to historical constraints on computational power.

\footnote{I note, in passing, that scholars in the field often allude to \citepos{Firth1957} quip ``you shall know a word by the company it keeps,'' (p. --) as seminal to distributional semantics.  I suggest that this turn of speech has actually been taken out of the context of Firth's intent, which was to consider the role of idioms in particular in a comprehensive programme of linguistic study at various levels of abstraction, a project which is probably actually very much at odds with purely statistical approaches to language.}

Notwithstanding \citepos{Chomsky} formidable case that the bulk of a language cannot be captured in numbers quantifying the relative situation of words, the fact remains that, when it comes to computational approaches to language, a matrix capturing the nature of some concordance or another remains one of the main games in town.  Two post-millennial developments have facilitated the rapid development of research into computational methods employing word counting approaches: the accretion of large-scale, widely available digitalised textual data, and the advent of computers with the processing power to efficiently handle data of this scale.

which characterise a natural language could possibly be found in a matrix of statistics about the way that words co-occur with one another across some corpus, regardless of how comprehensive the data may be.

On the other hand, in as much as computational approaches to language modelling are concerned, co-occurrence statistics are the main game in town.

\section{OLD}
At its heart, this is a project about the potential for symbol manipulating machines to model creativity, and in particular the creative use of language.  Computational Creativity is a field that, as \cite{Wiggins2006b} puts it, uses ``computational means and methods'' to study ``behaviour exhibited by natural and artificial systems, which would be deemed creative if exhibited by humans,'' (p. 210).  At stake here is the problem of what creativity actually is, and, as \cite{Colton} have said, the concept of creativity must be \emph{essentially contested}.  Nonetheless, a basic position will be taken here that at the root of creativity is, in the spirit of \cite{Wittgenstein1953}, an act of meaning-making, by which a new way of conceptually representing something in the world comes about.

The prevalent take on computational creativity has focused on an AI approach involving the traversal of state spaces for potential creative artefacts, a methodology with deep roots in \cite{Boden1990}.  Philosophical problems with this essentially symbolic mode of generation have been illustrated by \cite{McGregorEA2014}, though: the dependency on preconditioned representations remits little in the way of actual creative behaviour on the part of the symbol manipulating agent.  Here the hard question of evaluation comes up, and the evaluative challenges peculiar to computational creativity have been addressed by \cite{Ritchie2007}, \cite{ColtonEA2012B}, and \cite{Jordanous2012}, to name a few.  At the core of this project is the proposal that, for an agent to be perceived as genuinely and autonomously instigating meaning-making, there has to be at least a nominal notion of the trafficking of dynamic, interactive representations within the agent's cognitive framework.  It is here that computational creativity will serve as a compass to keep this project on course: by returning to the question of whether the model outlined here can be described as an agent that is behaving creatively, the pragmatic issue of the role of contextualisation in the actual use of language will stay central to the thesis.

In addition to a general survey of the field, this project's particular commitment to conceptualisation and metaphor invites a survey of the appreciable work done in the computational production of metaphor and analogy.  With roots in the conceptual blending theory of \cite{Turner}, this area has been explored more recently by the likes of \cite{VealeEA2007} and \cite{O'Donoghue}.  Additional attention is due to work in poetry generation coming from \cite{Gervas}, \cite{Toivonen}, \cite{Rashel}, \cite{Cardosa}, and others.

\section{Minds and Spaces}
\cite{Davidson} cautions against considering language as an ``organising system'' (p. 11) for conceptual schemes.  In the process of understanding a sentence, a contextually specific theory of meaning is devised on the spot, so to speak, that permits ``an acceptable theory of belief'' (p. 18) regarding the sentence's author.  This means, though, that the conceptual organisation supposedly inherent in language is in fact a fleeting artefact that temporarily props up a momentary propositional stance, and language is just a mechanism for groping towards some sort of understanding between communicants regarding positions on the relationship between meaning and belief.  A consequence of this theoretical insight is the temptation to resort to a view such as that taken by \cite{Clark}, who holds that language is ``a cognition-enhancing animal-built structure,'' (p. 370).

The theoretical premise of this project is that a structural, spatial, geometric language model can successfully capture significant aspects of conceptualisation.  In this regard, the work is grounded in the theories of \cite{Gardenfors} and \cite{Widdows}.  G\"{a}rdenfors in particular postulates a kind of cognitive middle ground where conceptual spaces, characterised by coherent dimensions which map to features of concepts, stand between low level stimuli and high level symbolic representations.  Widdows, on the other hand, is more concerned with the description of a language model where a geometry of words facilitates the mechanisms of logic.  In both cases, these authors provide insight into the way that a specifically geometric view of representations allows for the dynamic interaction of symbols by way of using language as a cognitively productive system.

This project's commitment to building a system which remits evidence of dynamic representational structures is admittedly reminiscent of \cite{Fodor}, who holds that concepts are fundamentally compositional mental entities.  Any nativist forebodings engendered here are diffused somewhat by \citepos{Putnam} insight that conceptual extension cannot strictly be found ``in the head'' (p. 170).  In this regard, work in embodied cognitive science, rooted in the enactivism of \cite{Varela}, provides the cognitive foundation for a spatially charged theory of concepts.  So \cite{Thompson} goes on to offer a definition of information as ``the intentional relation of the system to its milieu,'' (p. 59), a view which attempts to capture the tight relationship between the spatial situation of the world and the symbolic representation of that situation \citep[][is another notable proponent of this approach]{Pattee}.  Similarly, the Heideggarian account of \cite{Wheeler}, with reference to \cite{Clark}, postulates an \emph{action-oriented representation} where the very structural nature of representations are ``deeply dependent on the specific context of action,'' (p. 196).  In the end the theory of language embraced here will be characterised by \citepos{Gibson} notion of \emph{affordances}: just as with physical objects, words present themselves as opportunities for communication, and it is in the ready-to-hand appropriation of meaning that the genesis of metaphor is to be discovered.

\section{Words and Concepts}
In the spirit of \cite{Peirce}, this thesis is predicated on the idea that the signs constituting a language are involved in a physically grounded process that is perpetually unfolding in tight entanglement with the world.  As mentioned in the previous section, this stance leads on to the view that the compositional components of a language offer themselves as affordances for communication in the context of a particular environmental situation.  It is by virtue of this opportunistic seizing of linguistic units as operational elements in a system of contextualised conceptual representation that language becomes so readily figurative.  And it is here the work connects with the theories of metaphor produced by \cite{Black} and \cite{Lakoff}, who see figurative language as interactions between isomorphic conceptual structures of one sort or another.

The account of metaphor as a simple process of intensional projection, such as that offered by \cite{Searle}, is confounded by \cite{Davidson}, who makes a controversial but ultimately persuasive case for the idea that so-called figurative language must in fact be interpreted literally because the pragmatically meaningful component of metaphor transpires on a level which is non-sentential.  \cite{Carston} fleshes out this claim, drawing on the inherently \emph{imagistic} quality of metaphor to offer an account of how the conceptual economy inherent in figurative expression involves components that cannot possibly be captured propositionally.  Similarly, \cite{Reimer} draws out a distinction between the \emph{meaning} and the \emph{intimation} of a metaphor, concluding that it is this second, no-propositional quality that gives figurative language its distinct character.

At stake here is a basic notion about the contextual nature of conceptualisation, something that \cite{Barsalou} has described in terms of the \emph{haphazard} way in which concepts are formed in response to a situation in an environment.  In the same vein, it is again \cite{Carston} who, from a relevance theoretical perspective, has characterised the formulation of concepts as \emph{ad hoc}, in particular analysing the way in which meaning is appropriated for some pragmatic purpose in the course of metaphor making.  In response to Carston, \cite{Allott} have made the case that \emph{ad hoc} concepts cannot possibly be \emph{atomic}, preferring instead to view concept formation as a process of inference involving some sort of clustering of information on a contextual basis.

This last theory of conceptualisation as a process of informational clustering begins to look a lot like the computational model that will be described in this thesis.  By pushing these clusters into an explicitly geometric representation, the hope is that a kind of non-propositional structure will emerge, satisfying apt points regarding the nature of metaphor raised by Davidson and his acolytes and, at the same time, providing a concrete basis for the sort of conceptually anatomic mapping proposed by Lakoff and Johnson.  Viewed in this light, computational linguistics, with its propensity for the construction of informational structures in a high-dimensional space, becomes the natural domain for a dynamically unfolding, context sensitive model of figurative language.

\section{Computers and Language}
At last, from a practical perspective, this work must be placed in relation to the ongoing work in computational linguistics, and in particular on the type of high dimensional, corpus based, generally unsupervised language modelling that will be at the core of the project presented here.  The idea that statistical word representations can be constructed in such a way as to be dynamically interactive is inherent in the work on compositionality done by, for instance, \cite{CoeckeEA2011} and \cite{GreffenstetteEA2011} \citep[see][for an overview]{MitchellEA2010}.  While the model described in this thesis does not target compositionality, the idea that linguistic representations can only capture conceptualisation by being somehow dynamically interactive is implicit in distributional semantic approaches to compositionality.

In terms of vector space models of distributional semantics in general, \cite{Clark2015} offers a good contemporary overview of work in the field.  The model described here, populated as it is by literal co-occurrence statistics rather than abstract values learned through iterations over a weighted network, distinguishes itself from the ongoing trend towards models with abstract dimensions, which can trace its roots back to the matrix factorisation based techniques developed by, for instance, \cite{DeerwesterEA1990} and \cite{BleiEA2003}.  More recently, the neural network based approaches of, for instance, \cite{BengioEA2003}, \cite{CollobertEA2008}, and \cite{MikolovEA2013} have achieved impressive results.  Mikolov et al in particular, along with \cite{PenningtonEA2014}, who present a model involving a hybrid of weighted networks and matrix factorisation, have achieved state-of-theart results on analogy completion tasks.  In the case of these models, however, the opacity of the scalars which constitute the word-spaces means there can be no hope of capturing the contextually informed theory of conceptualisation surveyed in the previous section.  Instead, to the degree that context is captured at all, it is found in the multiplicity of directions of movement offered by the dimensionality of the one irreducible space.  Ultimately, it seems that the analogy test sets which these systems target really just embodied a very specific type of figurative language, and subsequent systems have, by focusing on this particular objective, built this specificity into their own procedures.

Beyond analogy, ongoing work in taxonomy completion and, more generally, the inferential capacities of statistical language models is germane to the project described in this thesis.  To this end, work from \cite{CimianoEA2003} and \cite{SnowEA2006} provides a good exemplar of current directions in the field.  More recently, \cite{SantusEA2014} have presented an energy based model for determining hypernymy based on lexical statistics, while \cite{LevyEA2015} have offered a rebuttal to some of the ongoing work in the area, suggesting that a range of supervised learning language models actually do not recognise conceptual relationships between words, but rather simply model the probability of a term being used to describe a categorical \emph{prototype}.  In related work, \cite{SocherEA2013} have proposed a neural tensor model for completing knowledge bases, again with impressive results.

Ultimately there is a certain correlation between the project described in this thesis and the comprehensive objective of research from \cite{BaroniEA2010b}, who describe a generalised statistical language model designed to perform well on a wide array of language processing tasks.  Elsewhere, \citepos{BaroniEA2010} work on composing adjective-noun pairs into singular vector representations is also relevant, as the adjective, represented on its own as a matrix, might be taken as a contextualising mechanism.
